
Modify this deepspeed zero stage 3 config to ues parameter offloading.
{
  "bf16": {
      "enabled": true
  },
  "train_micro_batch_size_per_gpu": "auto",
  "zero_optimization": {
      "stage": 3,
      "offload_optimizer": {
          "device": "none"
      },
      "offload_param": {
          "device": "none"
      },
      "overlap_comm": true,
      "contiguous_gradients": true,
      "reduce_bucket_size": 5e8,
      "stage3_prefetch_bucket_size": 5e8,
      "stage3_param_persistence_threshold": 0,
      "stage3_max_live_parameters": 0,
      "stage3_max_reuse_distance": 0,
      "gather_16bit_weights_on_model_save": true
  }
}

To enable parameter offloading in your DeepSpeed ZeRO Stage 3 configuration, you need to change the offload_param device from "none" to either "cpu" or "nvme". Here's the modified config:


DeepSpeed ZeRO Stage 3 Config with Parameter Offloading
Code 
The key change is in the offload_param section where I changed "device": "none" to "device": "cpu". This will offload parameters to CPU memory, which can significantly reduce GPU memory usage at the cost of some performance overhead due to data transfers between CPU and GPU.

If you have NVMe storage available and want even more aggressive offloading, you could use "device": "nvme" instead, but this typically has higher latency than CPU offloading.

You might also want to consider enabling optimizer offloading by changing offload_optimizer device to "cpu" if you need




{
  "bf16": {
      "enabled": true
  },
  "train_micro_batch_size_per_gpu": "auto",
  "zero_optimization": {
      "stage": 3,
      "offload_optimizer": {
          "device": "none"
      },
      "offload_param": {
          "device": "cpu"
      },
      "overlap_comm": true,
      "contiguous_gradients": true,
      "reduce_bucket_size": 5e8,
      "stage3_prefetch_bucket_size": 5e8,
      "stage3_param_persistence_threshold": 0,
      "stage3_max_live_parameters": 0,
      "stage3_max_reuse_distance": 0,
      "gather_16bit_weights_on_model_save": true
  }
}
