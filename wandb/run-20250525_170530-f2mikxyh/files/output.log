  0%|          | 0/351 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/fs01/projects/cft_vlm/Qwen2.5-VL/qwen-vl-finetune/qwenvl/train/train_qwen.py", line 178, in <module>
    train(attn_implementation="flash_attention_2")
  File "/fs01/projects/cft_vlm/Qwen2.5-VL/qwen-vl-finetune/qwenvl/train/train_qwen.py", line 168, in train
    trainer.train()
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/transformers/trainer.py", line 2240, in train
    return inner_training_loop(
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/transformers/trainer.py", line 2555, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/transformers/trainer.py", line 3745, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/transformers/trainer.py", line 3810, in compute_loss
    outputs = model(**inputs)
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1845, in _call_impl
    return inner()
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1793, in inner
    result = forward_call(*args, **kwargs)
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/transformers/utils/generic.py", line 969, in wrapper
    output = func(self, *args, **kwargs)
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 1908, in forward
    outputs = self.model(
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1845, in _call_impl
    return inner()
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1793, in inner
    result = forward_call(*args, **kwargs)
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 1678, in forward
    video_embeds = self.get_video_features(pixel_values_videos, video_grid_thw)
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 1600, in get_video_features
    video_embeds = self.visual(pixel_values_videos, grid_thw=video_grid_thw)
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1845, in _call_impl
    return inner()
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1793, in inner
    result = forward_call(*args, **kwargs)
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 526, in forward
    hidden_states = self._gradient_checkpointing_func(
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/_compile.py", line 32, in inner
    return disable_fn(*args, **kwargs)
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 745, in _fn
    return fn(*args, **kwargs)
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py", line 489, in checkpoint
    return CheckpointFunction.apply(function, preserve, *args)
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/autograd/function.py", line 575, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py", line 264, in forward
    outputs = run_function(*args)
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1845, in _call_impl
    return inner()
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1793, in inner
    result = forward_call(*args, **kwargs)
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 341, in forward
    hidden_states = hidden_states + self.attn(
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1845, in _call_impl
    return inner()
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1793, in inner
    result = forward_call(*args, **kwargs)
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 194, in forward
    attn_output = flash_attn_varlen_func(q, k, v, cu_seqlens, cu_seqlens, max_seqlen, max_seqlen).reshape(
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py", line 1448, in flash_attn_varlen_func
    return FlashAttnVarlenFunc.apply(
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/autograd/function.py", line 575, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py", line 930, in forward
    out_padded, softmax_lse, S_dmask, rng_state = _wrapped_flash_attn_varlen_forward(
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/_ops.py", line 1123, in __call__
    return self._op(*args, **(kwargs or {}))
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/_library/autograd.py", line 113, in autograd_impl
    result = forward_no_grad(*args, Metadata(keyset, keyword_only_args))
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/_library/autograd.py", line 40, in forward_no_grad
    result = op.redispatch(keyset & _C._after_autograd_keyset, *args, **kwargs)
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/_ops.py", line 728, in redispatch
    return self._handle.redispatch_boxed(keyset, *args, **kwargs)
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/_library/custom_ops.py", line 305, in backend_impl
    result = self._backend_fns[device_type](*args, **kwargs)
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/_compile.py", line 32, in inner
    return disable_fn(*args, **kwargs)
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 745, in _fn
    return fn(*args, **kwargs)
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/_library/custom_ops.py", line 337, in wrapped_fn
    return fn(*args, **kwargs)
  File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py", line 170, in _flash_attn_varlen_forward
    out, softmax_lse, S_dmask, rng_state = flash_attn_gpu.varlen_fwd(
RuntimeError: FlashAttention only supports Ampere GPUs or newer.
[rank0]: Traceback (most recent call last):
[rank0]:   File "/fs01/projects/cft_vlm/Qwen2.5-VL/qwen-vl-finetune/qwenvl/train/train_qwen.py", line 178, in <module>
[rank0]:     train(attn_implementation="flash_attention_2")
[rank0]:   File "/fs01/projects/cft_vlm/Qwen2.5-VL/qwen-vl-finetune/qwenvl/train/train_qwen.py", line 168, in train
[rank0]:     trainer.train()
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/transformers/trainer.py", line 2240, in train
[rank0]:     return inner_training_loop(
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/transformers/trainer.py", line 2555, in _inner_training_loop
[rank0]:     tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/transformers/trainer.py", line 3745, in training_step
[rank0]:     loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/transformers/trainer.py", line 3810, in compute_loss
[rank0]:     outputs = model(**inputs)
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
[rank0]:     ret_val = func(*args, **kwargs)
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
[rank0]:     loss = self.module(*inputs, **kwargs)
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1845, in _call_impl
[rank0]:     return inner()
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1793, in inner
[rank0]:     result = forward_call(*args, **kwargs)
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/transformers/utils/generic.py", line 969, in wrapper
[rank0]:     output = func(self, *args, **kwargs)
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 1908, in forward
[rank0]:     outputs = self.model(
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1845, in _call_impl
[rank0]:     return inner()
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1793, in inner
[rank0]:     result = forward_call(*args, **kwargs)
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 1678, in forward
[rank0]:     video_embeds = self.get_video_features(pixel_values_videos, video_grid_thw)
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 1600, in get_video_features
[rank0]:     video_embeds = self.visual(pixel_values_videos, grid_thw=video_grid_thw)
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1845, in _call_impl
[rank0]:     return inner()
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1793, in inner
[rank0]:     result = forward_call(*args, **kwargs)
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 526, in forward
[rank0]:     hidden_states = self._gradient_checkpointing_func(
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/_compile.py", line 32, in inner
[rank0]:     return disable_fn(*args, **kwargs)
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 745, in _fn
[rank0]:     return fn(*args, **kwargs)
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py", line 489, in checkpoint
[rank0]:     return CheckpointFunction.apply(function, preserve, *args)
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/autograd/function.py", line 575, in apply
[rank0]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py", line 264, in forward
[rank0]:     outputs = run_function(*args)
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1845, in _call_impl
[rank0]:     return inner()
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1793, in inner
[rank0]:     result = forward_call(*args, **kwargs)
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 341, in forward
[rank0]:     hidden_states = hidden_states + self.attn(
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1845, in _call_impl
[rank0]:     return inner()
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1793, in inner
[rank0]:     result = forward_call(*args, **kwargs)
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 194, in forward
[rank0]:     attn_output = flash_attn_varlen_func(q, k, v, cu_seqlens, cu_seqlens, max_seqlen, max_seqlen).reshape(
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py", line 1448, in flash_attn_varlen_func
[rank0]:     return FlashAttnVarlenFunc.apply(
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/autograd/function.py", line 575, in apply
[rank0]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py", line 930, in forward
[rank0]:     out_padded, softmax_lse, S_dmask, rng_state = _wrapped_flash_attn_varlen_forward(
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/_ops.py", line 1123, in __call__
[rank0]:     return self._op(*args, **(kwargs or {}))
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/_library/autograd.py", line 113, in autograd_impl
[rank0]:     result = forward_no_grad(*args, Metadata(keyset, keyword_only_args))
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/_library/autograd.py", line 40, in forward_no_grad
[rank0]:     result = op.redispatch(keyset & _C._after_autograd_keyset, *args, **kwargs)
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/_ops.py", line 728, in redispatch
[rank0]:     return self._handle.redispatch_boxed(keyset, *args, **kwargs)
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/_library/custom_ops.py", line 305, in backend_impl
[rank0]:     result = self._backend_fns[device_type](*args, **kwargs)
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/_compile.py", line 32, in inner
[rank0]:     return disable_fn(*args, **kwargs)
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 745, in _fn
[rank0]:     return fn(*args, **kwargs)
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/torch/_library/custom_ops.py", line 337, in wrapped_fn
[rank0]:     return fn(*args, **kwargs)
[rank0]:   File "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py", line 170, in _flash_attn_varlen_forward
[rank0]:     out, softmax_lse, S_dmask, rng_state = flash_attn_gpu.varlen_fwd(
[rank0]: RuntimeError: FlashAttention only supports Ampere GPUs or newer.
