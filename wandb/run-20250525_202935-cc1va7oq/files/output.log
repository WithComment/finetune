  0%|          | 0/351 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.
                                                  
{'loss': 2.4461, 'grad_norm': 5.554298741035022, 'learning_rate': 0.0, 'epoch': 0.0}
{'loss': 2.424, 'grad_norm': 6.138911265928633, 'learning_rate': 1.818181818181818e-08, 'epoch': 0.0}
{'loss': 2.4265, 'grad_norm': 8.172444704231802, 'learning_rate': 3.636363636363636e-08, 'epoch': 0.0}
{'loss': 2.8066, 'grad_norm': 49.76996641203935, 'learning_rate': 5.454545454545454e-08, 'epoch': 0.01}
{'loss': 2.5687, 'grad_norm': 28.331391559781583, 'learning_rate': 7.272727272727273e-08, 'epoch': 0.01}
{'loss': 2.5181, 'grad_norm': 8.884023173999367, 'learning_rate': 9.09090909090909e-08, 'epoch': 0.01}
{'loss': 2.7087, 'grad_norm': 20.57982095752974, 'learning_rate': 1.0909090909090908e-07, 'epoch': 0.01}
{'loss': 2.42, 'grad_norm': 6.659408058594042, 'learning_rate': 1.2727272727272726e-07, 'epoch': 0.01}
{'loss': 2.4829, 'grad_norm': 26.06584301555192, 'learning_rate': 1.4545454545454545e-07, 'epoch': 0.01}
{'loss': 2.4166, 'grad_norm': 12.975904390084251, 'learning_rate': 1.6363636363636364e-07, 'epoch': 0.01}
{'loss': 2.5596, 'grad_norm': 9.754269629010047, 'learning_rate': 1.818181818181818e-07, 'epoch': 0.02}
{'loss': 2.3993, 'grad_norm': 12.56292445022644, 'learning_rate': 2e-07, 'epoch': 0.02}
{'loss': 2.6717, 'grad_norm': 23.459104420711032, 'learning_rate': 1.9999573117033678e-07, 'epoch': 0.02}
{'loss': 2.6652, 'grad_norm': 17.734052019890907, 'learning_rate': 1.9998292504580526e-07, 'epoch': 0.02}
{'loss': 2.5375, 'grad_norm': 6.128779640508607, 'learning_rate': 1.9996158271974872e-07, 'epoch': 0.02}
{'loss': 2.4507, 'grad_norm': 13.910529897662265, 'learning_rate': 1.999317060143023e-07, 'epoch': 0.02}
{'loss': 2.4623, 'grad_norm': 51.74897236336155, 'learning_rate': 1.9989329748023723e-07, 'epoch': 0.02}
{'loss': 2.3569, 'grad_norm': 5.840228590537209, 'learning_rate': 1.998463603967434e-07, 'epoch': 0.03}
{'loss': 2.3972, 'grad_norm': 10.376558878946307, 'learning_rate': 1.9979089877114903e-07, 'epoch': 0.03}
{'loss': 2.4799, 'grad_norm': 6.570378681677386, 'learning_rate': 1.997269173385788e-07, 'epoch': 0.03}
{'loss': 2.528, 'grad_norm': 16.68478624472516, 'learning_rate': 1.9965442156154943e-07, 'epoch': 0.03}
{'loss': 2.4111, 'grad_norm': 5.971655463987139, 'learning_rate': 1.9957341762950344e-07, 'epoch': 0.03}
{'loss': 2.4439, 'grad_norm': 6.191616853821269, 'learning_rate': 1.9948391245828055e-07, 'epoch': 0.03}
{'loss': 2.8321, 'grad_norm': 21.79927923065852, 'learning_rate': 1.9938591368952737e-07, 'epoch': 0.03}
{'loss': 2.4436, 'grad_norm': 6.121460121013432, 'learning_rate': 1.992794296900449e-07, 'epoch': 0.04}
[2025-05-25 20:42:05,869] [WARNING] [stage3.py:2148:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 2.767, 'grad_norm': 23.485574612245966, 'learning_rate': 1.9916446955107427e-07, 'epoch': 0.04}
{'loss': 2.6939, 'grad_norm': 22.26399130433241, 'learning_rate': 1.990410430875205e-07, 'epoch': 0.04}
{'loss': 2.3766, 'grad_norm': 5.902353547883357, 'learning_rate': 1.989091608371146e-07, 'epoch': 0.04}
{'loss': 2.2874, 'grad_norm': 6.902909993231466, 'learning_rate': 1.9876883405951376e-07, 'epoch': 0.04}
{'loss': 2.2664, 'grad_norm': 7.1160062182456985, 'learning_rate': 1.9862007473534024e-07, 'epoch': 0.04}
{'loss': 2.3204, 'grad_norm': 6.216719861103681, 'learning_rate': 1.9846289556515834e-07, 'epoch': 0.04}
{'loss': 2.3845, 'grad_norm': 8.610933610081963, 'learning_rate': 1.982973099683902e-07, 'epoch': 0.05}
{'loss': 2.4716, 'grad_norm': 6.454548772610013, 'learning_rate': 1.9812333208216984e-07, 'epoch': 0.05}
{'loss': 2.3359, 'grad_norm': 8.024056373713039, 'learning_rate': 1.9794097676013658e-07, 'epoch': 0.05}
{'loss': 2.3772, 'grad_norm': 7.179396532178558, 'learning_rate': 1.9775025957116657e-07, 'epoch': 0.05}
{'loss': 2.5233, 'grad_norm': 8.94136639843365, 'learning_rate': 1.9755119679804367e-07, 'epoch': 0.05}
{'loss': 2.4431, 'grad_norm': 6.368839802127595, 'learning_rate': 1.9734380543606927e-07, 'epoch': 0.05}
{'loss': 2.4792, 'grad_norm': 7.389852771928885, 'learning_rate': 1.9712810319161137e-07, 'epoch': 0.05}
{'loss': 2.5729, 'grad_norm': 7.876474875802534, 'learning_rate': 1.9690410848059275e-07, 'epoch': 0.06}
{'loss': 2.4189, 'grad_norm': 7.919974573607372, 'learning_rate': 1.9667184042691874e-07, 'epoch': 0.06}
{'loss': 2.5054, 'grad_norm': 13.421056421297607, 'learning_rate': 1.9643131886084446e-07, 'epoch': 0.06}
{'loss': 2.5911, 'grad_norm': 11.163686957614523, 'learning_rate': 1.961825643172819e-07, 'epoch': 0.06}
{'loss': 2.5532, 'grad_norm': 8.332252560139784, 'learning_rate': 1.959255980340465e-07, 'epoch': 0.06}
{'loss': 2.4608, 'grad_norm': 13.38744352458607, 'learning_rate': 1.9566044195004407e-07, 'epoch': 0.06}
{'loss': 2.4924, 'grad_norm': 17.45029030664505, 'learning_rate': 1.953871187033978e-07, 'epoch': 0.06}
{'loss': 2.348, 'grad_norm': 6.110302967485097, 'learning_rate': 1.9510565162951537e-07, 'epoch': 0.07}
{'loss': 2.5241, 'grad_norm': 6.808000473013208, 'learning_rate': 1.9481606475909656e-07, 'epoch': 0.07}
{'loss': 2.4988, 'grad_norm': 12.35815552379794, 'learning_rate': 1.9451838281608194e-07, 'epoch': 0.07}
{'loss': 2.4203, 'grad_norm': 13.3098134314346, 'learning_rate': 1.9421263121554162e-07, 'epoch': 0.07}
{'loss': 2.4131, 'grad_norm': 9.568397688726721, 'learning_rate': 1.9389883606150565e-07, 'epoch': 0.07}
{'loss': 2.3986, 'grad_norm': 26.120891688813515, 'learning_rate': 1.9357702414473524e-07, 'epoch': 0.07}
{'loss': 2.4762, 'grad_norm': 6.11589915822769, 'learning_rate': 1.9324722294043556e-07, 'epoch': 0.07}
{'loss': 2.4998, 'grad_norm': 11.882166563762299, 'learning_rate': 1.929094606059099e-07, 'epoch': 0.08}
{'loss': 2.3687, 'grad_norm': 5.7552102325147905, 'learning_rate': 1.9256376597815563e-07, 'epoch': 0.08}
{'loss': 2.5138, 'grad_norm': 4.770074150006593, 'learning_rate': 1.9221016857140242e-07, 'epoch': 0.08}
{'loss': 2.5453, 'grad_norm': 11.497217033249285, 'learning_rate': 1.918486985745923e-07, 'epoch': 0.08}
{'loss': 2.359, 'grad_norm': 5.35550276751734, 'learning_rate': 1.914793868488021e-07, 'epoch': 0.08}
{'loss': 2.5332, 'grad_norm': 11.289813101323697, 'learning_rate': 1.9110226492460885e-07, 'epoch': 0.08}
{'loss': 2.3577, 'grad_norm': 8.41611017681622, 'learning_rate': 1.9071736499939763e-07, 'epoch': 0.08}
{'loss': 2.5759, 'grad_norm': 9.84666022384221, 'learning_rate': 1.9032471993461286e-07, 'epoch': 0.09}
{'loss': 2.5381, 'grad_norm': 28.60568526398921, 'learning_rate': 1.8992436325295257e-07, 'epoch': 0.09}
{'loss': 2.3457, 'grad_norm': 5.850435235043099, 'learning_rate': 1.8951632913550623e-07, 'epoch': 0.09}
{'loss': 2.395, 'grad_norm': 5.709555080980439, 'learning_rate': 1.8910065241883678e-07, 'epoch': 0.09}
{'loss': 2.3513, 'grad_norm': 4.257731514113163, 'learning_rate': 1.8867736859200618e-07, 'epoch': 0.09}
{'loss': 2.6753, 'grad_norm': 8.504394524721647, 'learning_rate': 1.8824651379354558e-07, 'epoch': 0.09}
{'loss': 2.3718, 'grad_norm': 8.308783485246963, 'learning_rate': 1.878081248083698e-07, 'epoch': 0.09}
{'loss': 2.4497, 'grad_norm': 4.921092581934193, 'learning_rate': 1.8736223906463695e-07, 'epoch': 0.1}
{'loss': 2.4625, 'grad_norm': 6.599612333622126, 'learning_rate': 1.8690889463055283e-07, 'epoch': 0.1}
{'loss': 2.3915, 'grad_norm': 6.2213425734229295, 'learning_rate': 1.864481302111208e-07, 'epoch': 0.1}
{'loss': 2.5053, 'grad_norm': 7.026916974788874, 'learning_rate': 1.8597998514483723e-07, 'epoch': 0.1}
{'loss': 2.4798, 'grad_norm': 5.005709666985734, 'learning_rate': 1.855044994003331e-07, 'epoch': 0.1}
{'loss': 2.4095, 'grad_norm': 6.103621376810388, 'learning_rate': 1.850217135729614e-07, 'epoch': 0.1}
{'loss': 2.4655, 'grad_norm': 4.470207051587213, 'learning_rate': 1.8453166888133136e-07, 'epoch': 0.1}
{'loss': 2.4899, 'grad_norm': 7.5496405448778185, 'learning_rate': 1.8403440716378926e-07, 'epoch': 0.11}
{'loss': 2.4456, 'grad_norm': 10.518232963963579, 'learning_rate': 1.8352997087484654e-07, 'epoch': 0.11}
{'loss': 2.6164, 'grad_norm': 6.216852010624279, 'learning_rate': 1.8301840308155504e-07, 'epoch': 0.11}
{'loss': 2.5111, 'grad_norm': 9.61414803966837, 'learning_rate': 1.8249974745983021e-07, 'epoch': 0.11}
{'loss': 2.8952, 'grad_norm': 26.23569126428411, 'learning_rate': 1.8197404829072212e-07, 'epoch': 0.11}
{'loss': 2.6481, 'grad_norm': 12.500905180001354, 'learning_rate': 1.8144135045663482e-07, 'epoch': 0.11}
{'loss': 2.3604, 'grad_norm': 5.137458940249031, 'learning_rate': 1.8090169943749475e-07, 'epoch': 0.11}
{'loss': 2.3205, 'grad_norm': 6.234856431983845, 'learning_rate': 1.8035514130686734e-07, 'epoch': 0.12}
{'loss': 2.4537, 'grad_norm': 38.55939871368003, 'learning_rate': 1.7980172272802395e-07, 'epoch': 0.12}
{'loss': 2.328, 'grad_norm': 13.421801645075933, 'learning_rate': 1.7924149094995736e-07, 'epoch': 0.12}
{'loss': 2.3683, 'grad_norm': 8.631974021086549, 'learning_rate': 1.7867449380334833e-07, 'epoch': 0.12}
{'loss': 2.4844, 'grad_norm': 15.591721844076815, 'learning_rate': 1.7810077969648153e-07, 'epoch': 0.12}
{'loss': 2.5811, 'grad_norm': 5.8933457718323, 'learning_rate': 1.7752039761111296e-07, 'epoch': 0.12}
{'loss': 2.4844, 'grad_norm': 22.800131188071465, 'learning_rate': 1.769333970982879e-07, 'epoch': 0.12}
{'loss': 2.3898, 'grad_norm': 9.684066390290665, 'learning_rate': 1.7633982827411028e-07, 'epoch': 0.13}
{'loss': 2.4105, 'grad_norm': 6.348413005949749, 'learning_rate': 1.7573974181546427e-07, 'epoch': 0.13}
{'loss': 2.3986, 'grad_norm': 5.422325400986398, 'learning_rate': 1.7513318895568735e-07, 'epoch': 0.13}
{'loss': 2.4766, 'grad_norm': 5.9184076557838665, 'learning_rate': 1.7452022148019625e-07, 'epoch': 0.13}
{'loss': 2.3935, 'grad_norm': 10.513743221444198, 'learning_rate': 1.739008917220659e-07, 'epoch': 0.13}
{'loss': 2.4053, 'grad_norm': 11.439768132300285, 'learning_rate': 1.7327525255756114e-07, 'epoch': 0.13}
{'loss': 2.4246, 'grad_norm': 6.675674020565632, 'learning_rate': 1.726433574016224e-07, 'epoch': 0.13}
{'loss': 2.4398, 'grad_norm': 5.880696498378137, 'learning_rate': 1.7200526020330546e-07, 'epoch': 0.14}
{'loss': 2.3789, 'grad_norm': 5.221145707772113, 'learning_rate': 1.7136101544117523e-07, 'epoch': 0.14}
{'loss': 2.3077, 'grad_norm': 4.702335918835883, 'learning_rate': 1.7071067811865473e-07, 'epoch': 0.14}
{'loss': 2.5265, 'grad_norm': 4.5815866186031515, 'learning_rate': 1.7005430375932907e-07, 'epoch': 0.14}
{'loss': 2.4654, 'grad_norm': 4.5550966764732985, 'learning_rate': 1.6939194840220497e-07, 'epoch': 0.14}
{'loss': 2.4696, 'grad_norm': 5.3936838539927034, 'learning_rate': 1.6872366859692626e-07, 'epoch': 0.14}
{'loss': 2.4593, 'grad_norm': 15.737365365261882, 'learning_rate': 1.6804952139894615e-07, 'epoch': 0.14}
{'loss': 2.6527, 'grad_norm': 6.088928272837506, 'learning_rate': 1.6736956436465573e-07, 'epoch': 0.15}
{'loss': 2.5016, 'grad_norm': 8.832023757373863, 'learning_rate': 1.6668385554647012e-07, 'epoch': 0.15}
{'loss': 2.3163, 'grad_norm': 5.589236168240503, 'learning_rate': 1.659924534878723e-07, 'epoch': 0.15}
{'loss': 2.2988, 'grad_norm': 6.326897740330992, 'learning_rate': 1.6529541721841444e-07, 'epoch': 0.15}
{'loss': 2.3121, 'grad_norm': 23.812806162299083, 'learning_rate': 1.6459280624867872e-07, 'epoch': 0.15}
{'loss': 2.3397, 'grad_norm': 5.329259000758844, 'learning_rate': 1.6388468056519612e-07, 'epoch': 0.15}
{'loss': 2.3636, 'grad_norm': 4.590843370605726, 'learning_rate': 1.6317110062532508e-07, 'epoch': 0.15}
{'loss': 2.3679, 'grad_norm': 6.790846379160008, 'learning_rate': 1.6245212735208993e-07, 'epoch': 0.16}
{'loss': 2.2397, 'grad_norm': 5.867723987378116, 'learning_rate': 1.617278221289793e-07, 'epoch': 0.16}
{'loss': 2.3706, 'grad_norm': 6.577843292462856, 'learning_rate': 1.6099824679470565e-07, 'epoch': 0.16}
{'loss': 2.3861, 'grad_norm': 5.375990549214677, 'learning_rate': 1.6026346363792565e-07, 'epoch': 0.16}
{'loss': 2.2242, 'grad_norm': 6.69142430877975, 'learning_rate': 1.5952353539192188e-07, 'epoch': 0.16}
{'loss': 2.2922, 'grad_norm': 4.439909098537398, 'learning_rate': 1.5877852522924732e-07, 'epoch': 0.16}
{'loss': 2.4823, 'grad_norm': 11.330699641525229, 'learning_rate': 1.5802849675633156e-07, 'epoch': 0.16}
{'loss': 2.4029, 'grad_norm': 5.167245035467829, 'learning_rate': 1.572735140080505e-07, 'epoch': 0.17}
{'loss': 2.4974, 'grad_norm': 4.870530713594836, 'learning_rate': 1.5651364144225918e-07, 'epoch': 0.17}
{'loss': 2.4722, 'grad_norm': 6.055782826899006, 'learning_rate': 1.5574894393428854e-07, 'epoch': 0.17}
{'loss': 2.4177, 'grad_norm': 4.878493030401479, 'learning_rate': 1.549794867714067e-07, 'epoch': 0.17}
{'loss': 2.6402, 'grad_norm': 6.532242062901812, 'learning_rate': 1.5420533564724495e-07, 'epoch': 0.17}
{'loss': 2.3413, 'grad_norm': 8.780932765056972, 'learning_rate': 1.5342655665618882e-07, 'epoch': 0.17}
{'loss': 2.4058, 'grad_norm': 16.03324580491184, 'learning_rate': 1.5264321628773557e-07, 'epoch': 0.17}
{'loss': 2.646, 'grad_norm': 3.8484835007487366, 'learning_rate': 1.518553814208172e-07, 'epoch': 0.18}
{'loss': 2.5332, 'grad_norm': 19.799953951731954, 'learning_rate': 1.510631193180907e-07, 'epoch': 0.18}
{'loss': 2.4237, 'grad_norm': 5.57330524051298, 'learning_rate': 1.5026649762019536e-07, 'epoch': 0.18}
{'loss': 2.3591, 'grad_norm': 9.909721522501602, 'learning_rate': 1.494655843399779e-07, 'epoch': 0.18}
{'loss': 2.3917, 'grad_norm': 4.4351541206131255, 'learning_rate': 1.4866044785668562e-07, 'epoch': 0.18}
{'loss': 2.348, 'grad_norm': 5.667789137775244, 'learning_rate': 1.4785115691012864e-07, 'epoch': 0.18}
{'loss': 2.4347, 'grad_norm': 5.274755092542391, 'learning_rate': 1.4703778059481093e-07, 'epoch': 0.18}
{'loss': 2.6305, 'grad_norm': 11.538615461009396, 'learning_rate': 1.4622038835403132e-07, 'epoch': 0.19}
{'loss': 2.3767, 'grad_norm': 7.4519360784572015, 'learning_rate': 1.4539904997395468e-07, 'epoch': 0.19}
{'loss': 2.4263, 'grad_norm': 5.91517285694214, 'learning_rate': 1.4457383557765383e-07, 'epoch': 0.19}
{'loss': 2.5125, 'grad_norm': 11.016239968781068, 'learning_rate': 1.4374481561912265e-07, 'epoch': 0.19}
{'loss': 2.4574, 'grad_norm': 19.094407969578285, 'learning_rate': 1.429120608772609e-07, 'epoch': 0.19}
{'loss': 2.3707, 'grad_norm': 16.348032792329388, 'learning_rate': 1.4207564244983152e-07, 'epoch': 0.19}
{'loss': 2.3235, 'grad_norm': 4.456542584206269, 'learning_rate': 1.4123563174739034e-07, 'epoch': 0.19}
{'loss': 2.4401, 'grad_norm': 13.418624705745108, 'learning_rate': 1.4039210048718947e-07, 'epoch': 0.2}
{'loss': 2.5715, 'grad_norm': 6.758922267636259, 'learning_rate': 1.3954512068705424e-07, 'epoch': 0.2}
{'loss': 2.347, 'grad_norm': 4.591072703163831, 'learning_rate': 1.3869476465923452e-07, 'epoch': 0.2}
{'loss': 2.3792, 'grad_norm': 5.060871932407513, 'learning_rate': 1.3784110500423102e-07, 'epoch': 0.2}
{'loss': 2.2923, 'grad_norm': 7.267049776845428, 'learning_rate': 1.369842146045969e-07, 'epoch': 0.2}
{'loss': 2.4106, 'grad_norm': 6.57762097665528, 'learning_rate': 1.361241666187153e-07, 'epoch': 0.2}
{'loss': 2.3832, 'grad_norm': 6.421561863157785, 'learning_rate': 1.3526103447455323e-07, 'epoch': 0.2}
{'loss': 2.3736, 'grad_norm': 5.4838577227849505, 'learning_rate': 1.3439489186339281e-07, 'epoch': 0.21}
{'loss': 2.5461, 'grad_norm': 9.071161536532706, 'learning_rate': 1.3352581273353938e-07, 'epoch': 0.21}
{'loss': 2.565, 'grad_norm': 14.534774600032787, 'learning_rate': 1.3265387128400832e-07, 'epoch': 0.21}
{'loss': 2.5234, 'grad_norm': 17.621564671148047, 'learning_rate': 1.3177914195819015e-07, 'epoch': 0.21}
{'loss': 2.4223, 'grad_norm': 6.412274547462273, 'learning_rate': 1.3090169943749475e-07, 'epoch': 0.21}
{'loss': 2.2907, 'grad_norm': 5.025742540271425, 'learning_rate': 1.3002161863497527e-07, 'epoch': 0.21}
{'loss': 2.4344, 'grad_norm': 6.171109023832647, 'learning_rate': 1.2913897468893246e-07, 'epoch': 0.21}
{'loss': 2.5605, 'grad_norm': 9.25585874122641, 'learning_rate': 1.282538429564995e-07, 'epoch': 0.22}
{'loss': 2.444, 'grad_norm': 5.193093916599462, 'learning_rate': 1.273662990072083e-07, 'epoch': 0.22}
{'loss': 2.3356, 'grad_norm': 5.5617198727240895, 'learning_rate': 1.2647641861653758e-07, 'epoch': 0.22}
{'loss': 2.5822, 'grad_norm': 3.995590759765686, 'learning_rate': 1.2558427775944357e-07, 'epoch': 0.22}
{'loss': 2.5519, 'grad_norm': 8.108556678779685, 'learning_rate': 1.246899526038733e-07, 'epoch': 0.22}
{'loss': 2.3582, 'grad_norm': 5.1834423230086735, 'learning_rate': 1.2379351950426188e-07, 'epoch': 0.22}
{'loss': 2.6075, 'grad_norm': 4.529699055537294, 'learning_rate': 1.2289505499501342e-07, 'epoch': 0.22}
{'loss': 2.2532, 'grad_norm': 4.362581929261848, 'learning_rate': 1.2199463578396687e-07, 'epoch': 0.23}
{'loss': 2.406, 'grad_norm': 6.845964904311835, 'learning_rate': 1.21092338745847e-07, 'epoch': 0.23}
{'loss': 2.4631, 'grad_norm': 16.976740626659154, 'learning_rate': 1.2018824091570102e-07, 'epoch': 0.23}
{'loss': 2.4266, 'grad_norm': 7.4927887780462115, 'learning_rate': 1.192824194823217e-07, 'epoch': 0.23}
{'loss': 2.2878, 'grad_norm': 5.74958544340991, 'learning_rate': 1.1837495178165705e-07, 'epoch': 0.23}
{'loss': 2.5028, 'grad_norm': 7.076978125624437, 'learning_rate': 1.1746591529020788e-07, 'epoch': 0.23}
{'loss': 2.3265, 'grad_norm': 6.229738629107213, 'learning_rate': 1.16555387618413e-07, 'epoch': 0.23}
{'loss': 2.3819, 'grad_norm': 4.532357957793012, 'learning_rate': 1.1564344650402309e-07, 'epoch': 0.24}
{'loss': 2.3622, 'grad_norm': 4.139788948577136, 'learning_rate': 1.1473016980546375e-07, 'epoch': 0.24}
{'loss': 2.3439, 'grad_norm': 10.833227677475627, 'learning_rate': 1.1381563549518822e-07, 'epoch': 0.24}
{'loss': 2.4332, 'grad_norm': 3.8786296828276527, 'learning_rate': 1.1289992165302033e-07, 'epoch': 0.24}
{'loss': 2.5483, 'grad_norm': 5.542077530428747, 'learning_rate': 1.1198310645948831e-07, 'epoch': 0.24}
{'loss': 2.14, 'grad_norm': 5.279358329133508, 'learning_rate': 1.1106526818915007e-07, 'epoch': 0.24}
{'loss': 2.2702, 'grad_norm': 17.269321239303387, 'learning_rate': 1.101464852039103e-07, 'epoch': 0.24}
{'loss': 2.3586, 'grad_norm': 6.55700903606256, 'learning_rate': 1.092268359463302e-07, 'epoch': 0.25}
{'loss': 2.6372, 'grad_norm': 4.936654611398372, 'learning_rate': 1.0830639893293039e-07, 'epoch': 0.25}
{'loss': 2.3912, 'grad_norm': 5.2607932436160265, 'learning_rate': 1.073852527474874e-07, 'epoch': 0.25}
{'loss': 2.3778, 'grad_norm': 9.399855112500756, 'learning_rate': 1.0646347603432442e-07, 'epoch': 0.25}
{'loss': 2.3156, 'grad_norm': 11.694904683721461, 'learning_rate': 1.05541147491597e-07, 'epoch': 0.25}
{'loss': 2.3085, 'grad_norm': 6.440743811543088, 'learning_rate': 1.0461834586457397e-07, 'epoch': 0.25}
{'loss': 2.342, 'grad_norm': 4.383404221706716, 'learning_rate': 1.036951499389145e-07, 'epoch': 0.25}
{'loss': 2.4119, 'grad_norm': 5.795831234683339, 'learning_rate': 1.0277163853394164e-07, 'epoch': 0.26}
{'loss': 2.3983, 'grad_norm': 4.2445694642106355, 'learning_rate': 1.0184789049591299e-07, 'epoch': 0.26}
{'loss': 2.3362, 'grad_norm': 5.32309287913055, 'learning_rate': 1.0092398469128908e-07, 'epoch': 0.26}
{'loss': 2.3274, 'grad_norm': 3.8925298326251987, 'learning_rate': 1e-07, 'epoch': 0.26}
{'loss': 2.5001, 'grad_norm': 9.38037253322137, 'learning_rate': 9.907601530871092e-08, 'epoch': 0.26}
{'loss': 2.3215, 'grad_norm': 4.092131616063215, 'learning_rate': 9.815210950408702e-08, 'epoch': 0.26}
{'loss': 2.2865, 'grad_norm': 9.073187088604886, 'learning_rate': 9.722836146605837e-08, 'epoch': 0.26}
[2025-05-25 21:55:51,122] [WARNING] [stage3.py:2148:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 2.4906, 'grad_norm': 8.34966945504851, 'learning_rate': 9.630485006108551e-08, 'epoch': 0.27}
{'loss': 2.4233, 'grad_norm': 5.07608732628405, 'learning_rate': 9.538165413542607e-08, 'epoch': 0.27}
{'loss': 2.3599, 'grad_norm': 4.136426168531091, 'learning_rate': 9.4458852508403e-08, 'epoch': 0.27}
{'loss': 2.3545, 'grad_norm': 10.650489599577114, 'learning_rate': 9.353652396567557e-08, 'epoch': 0.27}
{'loss': 2.4688, 'grad_norm': 5.326942771626193, 'learning_rate': 9.26147472525126e-08, 'epoch': 0.27}
{'loss': 2.4615, 'grad_norm': 5.805398857861118, 'learning_rate': 9.169360106706961e-08, 'epoch': 0.27}
{'loss': 2.3786, 'grad_norm': 8.894232777978667, 'learning_rate': 9.077316405366981e-08, 'epoch': 0.27}
{'loss': 2.2972, 'grad_norm': 5.113245095491268, 'learning_rate': 8.985351479608971e-08, 'epoch': 0.28}
{'loss': 2.5994, 'grad_norm': 7.874750475554651, 'learning_rate': 8.893473181084992e-08, 'epoch': 0.28}
{'loss': 2.7008, 'grad_norm': 6.413643959565117, 'learning_rate': 8.801689354051169e-08, 'epoch': 0.28}
{'loss': 2.3634, 'grad_norm': 4.961098860885129, 'learning_rate': 8.710007834697969e-08, 'epoch': 0.28}
{'loss': 2.3629, 'grad_norm': 9.84320191560776, 'learning_rate': 8.618436450481181e-08, 'epoch': 0.28}
{'loss': 2.3103, 'grad_norm': 6.565483251730753, 'learning_rate': 8.526983019453623e-08, 'epoch': 0.28}
{'loss': 2.3903, 'grad_norm': 19.327822603681998, 'learning_rate': 8.435655349597689e-08, 'epoch': 0.28}
{'loss': 2.3805, 'grad_norm': 4.259452419921877, 'learning_rate': 8.344461238158699e-08, 'epoch': 0.29}
{'loss': 2.4393, 'grad_norm': 7.276161162189878, 'learning_rate': 8.25340847097921e-08, 'epoch': 0.29}
{'loss': 2.3308, 'grad_norm': 9.123486953107783, 'learning_rate': 8.162504821834295e-08, 'epoch': 0.29}
[2025-05-25 22:03:43,772] [WARNING] [stage3.py:2148:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 2.4636, 'grad_norm': 5.655872288460775, 'learning_rate': 8.071758051767831e-08, 'epoch': 0.29}
{'loss': 2.3967, 'grad_norm': 4.755410712881726, 'learning_rate': 7.9811759084299e-08, 'epoch': 0.29}
{'loss': 2.4026, 'grad_norm': 5.468095224881613, 'learning_rate': 7.890766125415303e-08, 'epoch': 0.29}
{'loss': 2.3424, 'grad_norm': 4.764504129506028, 'learning_rate': 7.800536421603316e-08, 'epoch': 0.29}
{'loss': 2.3482, 'grad_norm': 11.414180873212308, 'learning_rate': 7.710494500498662e-08, 'epoch': 0.3}
{'loss': 2.257, 'grad_norm': 4.456868462657603, 'learning_rate': 7.620648049573815e-08, 'epoch': 0.3}
{'loss': 2.4036, 'grad_norm': 3.665101209783657, 'learning_rate': 7.531004739612667e-08, 'epoch': 0.3}
{'loss': 2.4446, 'grad_norm': 5.6477678041977875, 'learning_rate': 7.441572224055644e-08, 'epoch': 0.3}
{'loss': 2.4058, 'grad_norm': 7.000355893516435, 'learning_rate': 7.352358138346241e-08, 'epoch': 0.3}
{'loss': 2.3955, 'grad_norm': 9.327834355675703, 'learning_rate': 7.263370099279171e-08, 'epoch': 0.3}
{'loss': 2.4731, 'grad_norm': 6.6715020294105, 'learning_rate': 7.174615704350049e-08, 'epoch': 0.3}
{'loss': 2.5115, 'grad_norm': 4.206090409210242, 'learning_rate': 7.086102531106753e-08, 'epoch': 0.31}
{'loss': 2.3954, 'grad_norm': 5.507262171654476, 'learning_rate': 6.997838136502473e-08, 'epoch': 0.31}
{'loss': 2.2648, 'grad_norm': 9.47819641373163, 'learning_rate': 6.909830056250527e-08, 'epoch': 0.31}
{'loss': 2.5213, 'grad_norm': 4.827309912791832, 'learning_rate': 6.822085804180984e-08, 'epoch': 0.31}
{'loss': 2.3693, 'grad_norm': 5.356831621683081, 'learning_rate': 6.734612871599168e-08, 'epoch': 0.31}
{'loss': 2.3163, 'grad_norm': 14.008779842914667, 'learning_rate': 6.647418726646064e-08, 'epoch': 0.31}
{'loss': 2.3036, 'grad_norm': 5.555480965358647, 'learning_rate': 6.560510813660718e-08, 'epoch': 0.31}
{'loss': 2.4251, 'grad_norm': 6.35563381317084, 'learning_rate': 6.473896552544674e-08, 'epoch': 0.31}
{'loss': 2.5175, 'grad_norm': 4.618418975003046, 'learning_rate': 6.387583338128471e-08, 'epoch': 0.32}
{'loss': 2.668, 'grad_norm': 5.777752547064132, 'learning_rate': 6.30157853954031e-08, 'epoch': 0.32}
{'loss': 2.3565, 'grad_norm': 6.1598671939054945, 'learning_rate': 6.215889499576898e-08, 'epoch': 0.32}
{'loss': 2.2912, 'grad_norm': 10.152186419631471, 'learning_rate': 6.130523534076548e-08, 'epoch': 0.32}
{'loss': 2.2405, 'grad_norm': 12.287696569253484, 'learning_rate': 6.045487931294575e-08, 'epoch': 0.32}
{'loss': 2.279, 'grad_norm': 5.7901937616255035, 'learning_rate': 5.96078995128105e-08, 'epoch': 0.32}
{'loss': 2.3214, 'grad_norm': 3.9460660384865447, 'learning_rate': 5.8764368252609664e-08, 'epoch': 0.32}
{'loss': 2.3491, 'grad_norm': 4.485169619208218, 'learning_rate': 5.792435755016852e-08, 'epoch': 0.33}
{'loss': 2.4532, 'grad_norm': 4.383007294273631, 'learning_rate': 5.70879391227391e-08, 'epoch': 0.33}
{'loss': 2.3866, 'grad_norm': 4.403980539475412, 'learning_rate': 5.625518438087737e-08, 'epoch': 0.33}
{'loss': 2.5884, 'grad_norm': 10.344282499131172, 'learning_rate': 5.542616442234618e-08, 'epoch': 0.33}
{'loss': 2.4901, 'grad_norm': 12.293991607746372, 'learning_rate': 5.460095002604532e-08, 'epoch': 0.33}
{'loss': 2.404, 'grad_norm': 4.920546875049447, 'learning_rate': 5.3779611645968694e-08, 'epoch': 0.33}
{'loss': 2.3805, 'grad_norm': 4.7484156626071234, 'learning_rate': 5.296221940518908e-08, 'epoch': 0.33}
{'loss': 2.5042, 'grad_norm': 13.472710941518864, 'learning_rate': 5.214884308987135e-08, 'epoch': 0.34}
{'loss': 2.2912, 'grad_norm': 68.23203671920395, 'learning_rate': 5.133955214331438e-08, 'epoch': 0.34}
{'loss': 2.6438, 'grad_norm': 10.930792115997727, 'learning_rate': 5.053441566002213e-08, 'epoch': 0.34}
{'loss': 2.4775, 'grad_norm': 7.324423956777924, 'learning_rate': 4.973350237980466e-08, 'epoch': 0.34}
{'loss': 2.3497, 'grad_norm': 9.07481804537755, 'learning_rate': 4.893688068190932e-08, 'epoch': 0.34}
{'loss': 2.392, 'grad_norm': 4.775928710277314, 'learning_rate': 4.814461857918278e-08, 'epoch': 0.34}
{'loss': 2.4301, 'grad_norm': 4.089527243151161, 'learning_rate': 4.7356783712264406e-08, 'epoch': 0.34}
{'loss': 2.3323, 'grad_norm': 5.175851127509757, 'learning_rate': 4.657344334381116e-08, 'epoch': 0.35}
{'loss': 2.4937, 'grad_norm': 4.798188000589438, 'learning_rate': 4.579466435275505e-08, 'epoch': 0.35}
{'loss': 2.3118, 'grad_norm': 4.145919062876235, 'learning_rate': 4.502051322859327e-08, 'epoch': 0.35}
{'loss': 2.3144, 'grad_norm': 5.476584116901789, 'learning_rate': 4.425105606571145e-08, 'epoch': 0.35}
{'loss': 2.7679, 'grad_norm': 4.656549719953756, 'learning_rate': 4.348635855774081e-08, 'epoch': 0.35}
{'loss': 2.3835, 'grad_norm': 4.605860124417336, 'learning_rate': 4.272648599194948e-08, 'epoch': 0.35}
{'loss': 2.3507, 'grad_norm': 5.542643862621189, 'learning_rate': 4.197150324366844e-08, 'epoch': 0.35}
{'loss': 2.4587, 'grad_norm': 6.118652352718509, 'learning_rate': 4.1221474770752695e-08, 'epoch': 0.36}
{'loss': 2.377, 'grad_norm': 6.4509673299313155, 'learning_rate': 4.047646460807813e-08, 'epoch': 0.36}
{'loss': 2.3562, 'grad_norm': 3.4961785557857734, 'learning_rate': 3.973653636207437e-08, 'epoch': 0.36}
{'loss': 2.4641, 'grad_norm': 7.450828169188602, 'learning_rate': 3.900175320529433e-08, 'epoch': 0.36}
{'loss': 2.4009, 'grad_norm': 6.943800300239415, 'learning_rate': 3.8272177871020716e-08, 'epoch': 0.36}
{'loss': 2.3243, 'grad_norm': 4.764669098842335, 'learning_rate': 3.7547872647910105e-08, 'epoch': 0.36}
{'loss': 2.4461, 'grad_norm': 4.779642882384898, 'learning_rate': 3.682889937467493e-08, 'epoch': 0.36}
{'loss': 2.4698, 'grad_norm': 22.26843255658584, 'learning_rate': 3.611531943480389e-08, 'epoch': 0.37}
{'loss': 2.4806, 'grad_norm': 6.943052366812165, 'learning_rate': 3.540719375132129e-08, 'epoch': 0.37}
{'loss': 2.2857, 'grad_norm': 4.480991380747751, 'learning_rate': 3.470458278158559e-08, 'epoch': 0.37}
{'loss': 2.3451, 'grad_norm': 5.191840235991283, 'learning_rate': 3.4007546512127763e-08, 'epoch': 0.37}
{'loss': 2.4741, 'grad_norm': 8.109109842152543, 'learning_rate': 3.331614445352989e-08, 'epoch': 0.37}
{'loss': 2.289, 'grad_norm': 8.417537613773197, 'learning_rate': 3.263043563534428e-08, 'epoch': 0.37}
{'loss': 2.473, 'grad_norm': 4.083292468300965, 'learning_rate': 3.195047860105384e-08, 'epoch': 0.37}
{'loss': 2.8922, 'grad_norm': 7.212553979684142, 'learning_rate': 3.127633140307373e-08, 'epoch': 0.38}
{'loss': 2.2734, 'grad_norm': 5.551371022844161, 'learning_rate': 3.0608051597795036e-08, 'epoch': 0.38}
{'loss': 2.3862, 'grad_norm': 4.151102645060133, 'learning_rate': 2.9945696240670904e-08, 'epoch': 0.38}
{'loss': 2.3129, 'grad_norm': 7.777955262733345, 'learning_rate': 2.928932188134525e-08, 'epoch': 0.38}
{'loss': 2.3249, 'grad_norm': 4.15302520710368, 'learning_rate': 2.8638984558824773e-08, 'epoch': 0.38}
{'loss': 2.3409, 'grad_norm': 5.0453237015599575, 'learning_rate': 2.7994739796694556e-08, 'epoch': 0.38}
{'loss': 2.3248, 'grad_norm': 10.427233642384493, 'learning_rate': 2.73566425983776e-08, 'epoch': 0.38}
{'loss': 2.3661, 'grad_norm': 5.716106156823359, 'learning_rate': 2.6724747442438877e-08, 'epoch': 0.39}
{'loss': 2.2127, 'grad_norm': 5.941379248075958, 'learning_rate': 2.60991082779341e-08, 'epoch': 0.39}
{'loss': 2.2542, 'grad_norm': 3.8523725183720767, 'learning_rate': 2.547977851980373e-08, 'epoch': 0.39}
{'loss': 2.3035, 'grad_norm': 6.227992059063414, 'learning_rate': 2.4866811044312664e-08, 'epoch': 0.39}
{'loss': 2.5067, 'grad_norm': 5.08057822998077, 'learning_rate': 2.426025818453572e-08, 'epoch': 0.39}
{'loss': 2.6109, 'grad_norm': 32.374200146323595, 'learning_rate': 2.36601717258897e-08, 'epoch': 0.39}
{'loss': 2.4572, 'grad_norm': 4.16084175002013, 'learning_rate': 2.3066602901712107e-08, 'epoch': 0.39}
{'loss': 2.3697, 'grad_norm': 4.591832524791651, 'learning_rate': 2.247960238888701e-08, 'epoch': 0.4}
{'loss': 2.2437, 'grad_norm': 6.996417746373415, 'learning_rate': 2.189922030351846e-08, 'epoch': 0.4}
{'loss': 2.6104, 'grad_norm': 21.651668794176274, 'learning_rate': 2.1325506196651675e-08, 'epoch': 0.4}
{'loss': 2.4408, 'grad_norm': 5.515036850513741, 'learning_rate': 2.0758509050042617e-08, 'epoch': 0.4}
{'loss': 2.4721, 'grad_norm': 4.852181831260519, 'learning_rate': 2.019827727197605e-08, 'epoch': 0.4}
{'loss': 2.3149, 'grad_norm': 4.586999012929084, 'learning_rate': 1.9644858693132625e-08, 'epoch': 0.4}
{'loss': 2.3818, 'grad_norm': 6.321159024318648, 'learning_rate': 1.9098300562505266e-08, 'epoch': 0.4}
{'loss': 2.164, 'grad_norm': 4.691762441871632, 'learning_rate': 1.855864954336517e-08, 'epoch': 0.41}
{'loss': 2.337, 'grad_norm': 59.62988739466325, 'learning_rate': 1.8025951709277898e-08, 'epoch': 0.41}
{'loss': 2.3299, 'grad_norm': 6.632167539019281, 'learning_rate': 1.750025254016978e-08, 'epoch': 0.41}
{'loss': 2.3627, 'grad_norm': 5.626711136113414, 'learning_rate': 1.698159691844495e-08, 'epoch': 0.41}
{'loss': 2.39, 'grad_norm': 5.13019134125301, 'learning_rate': 1.6470029125153463e-08, 'epoch': 0.41}
{'loss': 2.4265, 'grad_norm': 11.88796391849055, 'learning_rate': 1.596559283621074e-08, 'epoch': 0.41}
{'loss': 2.5037, 'grad_norm': 4.67926785136167, 'learning_rate': 1.5468331118668654e-08, 'epoch': 0.41}
{'loss': 2.3026, 'grad_norm': 5.991509680891761, 'learning_rate': 1.49782864270386e-08, 'epoch': 0.42}
{'loss': 2.3825, 'grad_norm': 4.9470135376239, 'learning_rate': 1.4495500599666899e-08, 'epoch': 0.42}
{'loss': 2.3133, 'grad_norm': 4.366592298878787, 'learning_rate': 1.4020014855162753e-08, 'epoch': 0.42}
{'loss': 2.3457, 'grad_norm': 4.193263188550411, 'learning_rate': 1.3551869788879211e-08, 'epoch': 0.42}
{'loss': 2.4303, 'grad_norm': 7.469247915057831, 'learning_rate': 1.3091105369447164e-08, 'epoch': 0.42}
{'loss': 2.4344, 'grad_norm': 5.167351672613907, 'learning_rate': 1.2637760935363052e-08, 'epoch': 0.42}
{'loss': 2.4292, 'grad_norm': 7.423909996689573, 'learning_rate': 1.2191875191630207e-08, 'epoch': 0.42}
{'loss': 2.2255, 'grad_norm': 4.391536716673346, 'learning_rate': 1.1753486206454433e-08, 'epoch': 0.43}
{'loss': 2.4302, 'grad_norm': 5.443429850301067, 'learning_rate': 1.132263140799381e-08, 'epoch': 0.43}
{'loss': 2.3958, 'grad_norm': 7.166256020165484, 'learning_rate': 1.089934758116322e-08, 'epoch': 0.43}
{'loss': 2.336, 'grad_norm': 6.879995847539319, 'learning_rate': 1.0483670864493776e-08, 'epoch': 0.43}
{'loss': 2.606, 'grad_norm': 5.736294202690386, 'learning_rate': 1.0075636747047445e-08, 'epoch': 0.43}
{'loss': 2.5814, 'grad_norm': 4.979085851054622, 'learning_rate': 9.675280065387114e-09, 'epoch': 0.43}
{'loss': 2.3453, 'grad_norm': 4.806734069033459, 'learning_rate': 9.282635000602345e-09, 'epoch': 0.43}
{'loss': 2.6808, 'grad_norm': 11.437296214627619, 'learning_rate': 8.897735075391155e-09, 'epoch': 0.44}
{'loss': 2.3737, 'grad_norm': 4.0807007495134835, 'learning_rate': 8.520613151197897e-09, 'epoch': 0.44}
{'loss': 2.4519, 'grad_norm': 5.449183789913963, 'learning_rate': 8.151301425407698e-09, 'epoch': 0.44}
{'loss': 2.4843, 'grad_norm': 8.084478504789129, 'learning_rate': 7.78983142859755e-09, 'epoch': 0.44}
{'loss': 2.6067, 'grad_norm': 5.915978908297043, 'learning_rate': 7.436234021844379e-09, 'epoch': 0.44}
{'loss': 2.4781, 'grad_norm': 4.966433061395103, 'learning_rate': 7.090539394090134e-09, 'epoch': 0.44}
{'loss': 2.4556, 'grad_norm': 5.121146954052341, 'learning_rate': 6.75277705956443e-09, 'epoch': 0.44}
{'loss': 2.4492, 'grad_norm': 4.218795283289363, 'learning_rate': 6.422975855264756e-09, 'epoch': 0.45}
{'loss': 2.4272, 'grad_norm': 4.536934187222108, 'learning_rate': 6.101163938494358e-09, 'epoch': 0.45}
{'loss': 2.3929, 'grad_norm': 7.102910477083858, 'learning_rate': 5.787368784458368e-09, 'epoch': 0.45}
{'loss': 2.5476, 'grad_norm': 6.27807747469656, 'learning_rate': 5.4816171839180524e-09, 'epoch': 0.45}
{'loss': 2.514, 'grad_norm': 7.356879788579808, 'learning_rate': 5.183935240903414e-09, 'epoch': 0.45}
{'loss': 2.4477, 'grad_norm': 4.320079751902633, 'learning_rate': 4.8943483704846465e-09, 'epoch': 0.45}
{'loss': 2.4445, 'grad_norm': 4.585517988580557, 'learning_rate': 4.612881296602189e-09, 'epoch': 0.45}
{'loss': 2.3147, 'grad_norm': 9.624718904786887, 'learning_rate': 4.339558049955927e-09, 'epoch': 0.46}
{'loss': 2.3961, 'grad_norm': 6.936541467569692, 'learning_rate': 4.074401965953511e-09, 'epoch': 0.46}
{'loss': 2.5401, 'grad_norm': 9.354802449000704, 'learning_rate': 3.8174356827180954e-09, 'epoch': 0.46}
{'loss': 2.3706, 'grad_norm': 8.341816766972064, 'learning_rate': 3.5686811391555163e-09, 'epoch': 0.46}
{'loss': 2.3711, 'grad_norm': 6.794976951159427, 'learning_rate': 3.3281595730812575e-09, 'epoch': 0.46}
{'loss': 2.5671, 'grad_norm': 4.397372190598911, 'learning_rate': 3.0958915194072456e-09, 'epoch': 0.46}
{'loss': 2.4024, 'grad_norm': 4.149408981235111, 'learning_rate': 2.8718968083886075e-09, 'epoch': 0.46}
{'loss': 2.4009, 'grad_norm': 4.075983131819997, 'learning_rate': 2.6561945639307136e-09, 'epoch': 0.47}
{'loss': 2.5905, 'grad_norm': 6.1679750677758705, 'learning_rate': 2.44880320195634e-09, 'epoch': 0.47}
{'loss': 2.5452, 'grad_norm': 5.246286284974292, 'learning_rate': 2.2497404288334245e-09, 'epoch': 0.47}
{'loss': 2.4176, 'grad_norm': 7.455955435533755, 'learning_rate': 2.059023239863411e-09, 'epoch': 0.47}
{'loss': 2.4396, 'grad_norm': 8.859982307960403, 'learning_rate': 1.876667917830155e-09, 'epoch': 0.47}
{'loss': 2.3872, 'grad_norm': 4.940226016717623, 'learning_rate': 1.7026900316098214e-09, 'epoch': 0.47}
{'loss': 2.3158, 'grad_norm': 4.6458740162069825, 'learning_rate': 1.5371044348416406e-09, 'epoch': 0.47}
{'loss': 2.4555, 'grad_norm': 4.265830886907534, 'learning_rate': 1.3799252646597425e-09, 'epoch': 0.48}
{'loss': 2.4843, 'grad_norm': 8.541358741605404, 'learning_rate': 1.231165940486234e-09, 'epoch': 0.48}
{'loss': 2.48, 'grad_norm': 22.890181296252834, 'learning_rate': 1.0908391628854042e-09, 'epoch': 0.48}
{'loss': 2.2683, 'grad_norm': 4.328223237711117, 'learning_rate': 9.589569124794915e-10, 'epoch': 0.48}
{'loss': 2.4099, 'grad_norm': 5.899994181132628, 'learning_rate': 8.355304489257253e-10, 'epoch': 0.48}
{'loss': 2.5608, 'grad_norm': 12.446188654828946, 'learning_rate': 7.205703099551041e-10, 'epoch': 0.48}
{'loss': 2.2583, 'grad_norm': 10.707813642682979, 'learning_rate': 6.14086310472639e-10, 'epoch': 0.48}
{'loss': 2.4246, 'grad_norm': 5.384508952645329, 'learning_rate': 5.160875417194455e-10, 'epoch': 0.49}
{'loss': 2.3775, 'grad_norm': 4.396750280765312, 'learning_rate': 4.265823704965532e-10, 'epoch': 0.49}
{'loss': 2.3155, 'grad_norm': 9.261404510884171, 'learning_rate': 3.4557843845054445e-10, 'epoch': 0.49}
{'loss': 2.4521, 'grad_norm': 6.2505814556052535, 'learning_rate': 2.7308266142119784e-10, 'epoch': 0.49}
{'loss': 2.6674, 'grad_norm': 6.489980666658795, 'learning_rate': 2.0910122885097192e-10, 'epoch': 0.49}
{'loss': 2.4052, 'grad_norm': 4.026472136090138, 'learning_rate': 1.5363960325660563e-10, 'epoch': 0.49}
{'loss': 2.5612, 'grad_norm': 5.388900016731813, 'learning_rate': 1.0670251976275802e-10, 'epoch': 0.49}
{'loss': 2.3668, 'grad_norm': 5.34242052001513, 'learning_rate': 6.829398569770938e-11, 'epoch': 0.5}
{'loss': 2.2822, 'grad_norm': 4.8993773358688895, 'learning_rate': 3.841728025125723e-11, 'epoch': 0.5}
{'loss': 2.4597, 'grad_norm': 6.896633416909654, 'learning_rate': 1.707495419472904e-11, 'epoch': 0.5}
{'loss': 2.272, 'grad_norm': 4.960474565989773, 'learning_rate': 4.26882966321207e-12, 'epoch': 0.5}
{'train_runtime': 9793.186, 'train_samples_per_second': 1.146, 'train_steps_per_second': 0.036, 'train_loss': 2.4301258974265507, 'epoch': 0.5}
