  0%|          | 0/351 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.
                                                  
{'loss': 2.4772, 'grad_norm': 9.868203021313802, 'learning_rate': 0.0, 'epoch': 0.0}
{'loss': 2.5187, 'grad_norm': 12.739870452871632, 'learning_rate': 1.818181818181818e-08, 'epoch': 0.0}
{'loss': 2.4216, 'grad_norm': 6.873931064246492, 'learning_rate': 3.636363636363636e-08, 'epoch': 0.0}
{'loss': 2.5514, 'grad_norm': 15.831186558723076, 'learning_rate': 5.454545454545454e-08, 'epoch': 0.01}
{'loss': 2.4566, 'grad_norm': 6.387951546104096, 'learning_rate': 7.272727272727273e-08, 'epoch': 0.01}
{'loss': 2.7111, 'grad_norm': 32.68811268893348, 'learning_rate': 9.09090909090909e-08, 'epoch': 0.01}
{'loss': 2.3224, 'grad_norm': 5.908539361665391, 'learning_rate': 1.0909090909090908e-07, 'epoch': 0.01}
{'loss': 2.3999, 'grad_norm': 5.9603398909980845, 'learning_rate': 1.2727272727272726e-07, 'epoch': 0.01}
{'loss': 2.4953, 'grad_norm': 11.932131540604955, 'learning_rate': 1.4545454545454545e-07, 'epoch': 0.01}
{'loss': 2.503, 'grad_norm': 6.576027044068158, 'learning_rate': 1.6363636363636364e-07, 'epoch': 0.01}
{'loss': 2.6088, 'grad_norm': 6.393029061300904, 'learning_rate': 1.818181818181818e-07, 'epoch': 0.02}
{'loss': 2.4005, 'grad_norm': 6.129361191614803, 'learning_rate': 2e-07, 'epoch': 0.02}
{'loss': 2.4106, 'grad_norm': 8.109113286400836, 'learning_rate': 1.9999573117033678e-07, 'epoch': 0.02}
{'loss': 2.3512, 'grad_norm': 8.529060910535136, 'learning_rate': 1.9998292504580526e-07, 'epoch': 0.02}
{'loss': 2.389, 'grad_norm': 4.882715397167272, 'learning_rate': 1.9996158271974872e-07, 'epoch': 0.02}
{'loss': 2.6931, 'grad_norm': 6.003536786775085, 'learning_rate': 1.999317060143023e-07, 'epoch': 0.02}
{'loss': 2.4258, 'grad_norm': 6.905823303784537, 'learning_rate': 1.9989329748023723e-07, 'epoch': 0.02}
{'loss': 2.4053, 'grad_norm': 4.956693535250632, 'learning_rate': 1.998463603967434e-07, 'epoch': 0.03}
{'loss': 2.3694, 'grad_norm': 6.124430426506432, 'learning_rate': 1.9979089877114903e-07, 'epoch': 0.03}
{'loss': 2.5864, 'grad_norm': 7.420835536155222, 'learning_rate': 1.997269173385788e-07, 'epoch': 0.03}
{'loss': 2.5263, 'grad_norm': 6.132348445510852, 'learning_rate': 1.9965442156154943e-07, 'epoch': 0.03}
{'loss': 2.5359, 'grad_norm': 15.174579230759834, 'learning_rate': 1.9957341762950344e-07, 'epoch': 0.03}
{'loss': 2.4607, 'grad_norm': 5.986227600240746, 'learning_rate': 1.9948391245828055e-07, 'epoch': 0.03}
{'loss': 2.4397, 'grad_norm': 6.3539222115551715, 'learning_rate': 1.9938591368952737e-07, 'epoch': 0.03}
{'loss': 2.3848, 'grad_norm': 7.911603371923082, 'learning_rate': 1.992794296900449e-07, 'epoch': 0.04}
{'loss': 2.2767, 'grad_norm': 7.5592180598894085, 'learning_rate': 1.9916446955107427e-07, 'epoch': 0.04}
{'loss': 2.4019, 'grad_norm': 8.764321622670124, 'learning_rate': 1.990410430875205e-07, 'epoch': 0.04}
{'loss': 2.4254, 'grad_norm': 6.150111785046967, 'learning_rate': 1.989091608371146e-07, 'epoch': 0.04}
{'loss': 2.3719, 'grad_norm': 15.74038043090466, 'learning_rate': 1.9876883405951376e-07, 'epoch': 0.04}
{'loss': 2.5912, 'grad_norm': 13.050518164713191, 'learning_rate': 1.9862007473534024e-07, 'epoch': 0.04}
{'loss': 2.4009, 'grad_norm': 5.626489568391758, 'learning_rate': 1.9846289556515834e-07, 'epoch': 0.04}
{'loss': 2.544, 'grad_norm': 10.175264124753623, 'learning_rate': 1.982973099683902e-07, 'epoch': 0.05}
{'loss': 2.4009, 'grad_norm': 6.576659684802096, 'learning_rate': 1.9812333208216984e-07, 'epoch': 0.05}
{'loss': 2.5931, 'grad_norm': 21.439157789785156, 'learning_rate': 1.9794097676013658e-07, 'epoch': 0.05}
{'loss': 2.423, 'grad_norm': 5.707483849161579, 'learning_rate': 1.9775025957116657e-07, 'epoch': 0.05}
{'loss': 2.5036, 'grad_norm': 9.251764906570255, 'learning_rate': 1.9755119679804367e-07, 'epoch': 0.05}
{'loss': 2.3581, 'grad_norm': 11.780058406571404, 'learning_rate': 1.9734380543606927e-07, 'epoch': 0.05}
{'loss': 2.5774, 'grad_norm': 15.592979837090532, 'learning_rate': 1.9712810319161137e-07, 'epoch': 0.05}
{'loss': 2.4549, 'grad_norm': 9.355397798144681, 'learning_rate': 1.9690410848059275e-07, 'epoch': 0.06}
{'loss': 2.4084, 'grad_norm': 13.850815888918751, 'learning_rate': 1.9667184042691874e-07, 'epoch': 0.06}
{'loss': 2.4994, 'grad_norm': 7.196267441453546, 'learning_rate': 1.9643131886084446e-07, 'epoch': 0.06}
{'loss': 2.4749, 'grad_norm': 11.067393956266633, 'learning_rate': 1.961825643172819e-07, 'epoch': 0.06}
{'loss': 2.6146, 'grad_norm': 15.052797289529273, 'learning_rate': 1.959255980340465e-07, 'epoch': 0.06}
{'loss': 2.3908, 'grad_norm': 19.88300579687059, 'learning_rate': 1.9566044195004407e-07, 'epoch': 0.06}
{'loss': 2.3306, 'grad_norm': 10.36452343345164, 'learning_rate': 1.953871187033978e-07, 'epoch': 0.06}
{'loss': 2.3889, 'grad_norm': 6.271664373360688, 'learning_rate': 1.9510565162951537e-07, 'epoch': 0.07}
{'loss': 2.4671, 'grad_norm': 8.618937864491862, 'learning_rate': 1.9481606475909656e-07, 'epoch': 0.07}
{'loss': 2.399, 'grad_norm': 5.787538011076042, 'learning_rate': 1.9451838281608194e-07, 'epoch': 0.07}
{'loss': 2.4095, 'grad_norm': 6.002845090563826, 'learning_rate': 1.9421263121554162e-07, 'epoch': 0.07}
{'loss': 2.4642, 'grad_norm': 6.858934756711574, 'learning_rate': 1.9389883606150565e-07, 'epoch': 0.07}
{'loss': 2.5274, 'grad_norm': 12.3522889713858, 'learning_rate': 1.9357702414473524e-07, 'epoch': 0.07}
{'loss': 2.2164, 'grad_norm': 6.491819544051338, 'learning_rate': 1.9324722294043556e-07, 'epoch': 0.07}
{'loss': 2.4053, 'grad_norm': 5.747590659365834, 'learning_rate': 1.929094606059099e-07, 'epoch': 0.08}
{'loss': 2.5616, 'grad_norm': 10.667448772512229, 'learning_rate': 1.9256376597815563e-07, 'epoch': 0.08}
{'loss': 2.4921, 'grad_norm': 13.324516956904006, 'learning_rate': 1.9221016857140242e-07, 'epoch': 0.08}
{'loss': 2.3994, 'grad_norm': 6.115551998186678, 'learning_rate': 1.918486985745923e-07, 'epoch': 0.08}
{'loss': 2.6293, 'grad_norm': 8.091472476495687, 'learning_rate': 1.914793868488021e-07, 'epoch': 0.08}
{'loss': 2.4681, 'grad_norm': 4.525035925712195, 'learning_rate': 1.9110226492460885e-07, 'epoch': 0.08}
{'loss': 2.4772, 'grad_norm': 7.5284598226628106, 'learning_rate': 1.9071736499939763e-07, 'epoch': 0.08}
{'loss': 2.4606, 'grad_norm': 18.413819103981233, 'learning_rate': 1.9032471993461286e-07, 'epoch': 0.09}
{'loss': 2.4755, 'grad_norm': 8.491556425322447, 'learning_rate': 1.8992436325295257e-07, 'epoch': 0.09}
{'loss': 2.5557, 'grad_norm': 5.186842737280032, 'learning_rate': 1.8951632913550623e-07, 'epoch': 0.09}
{'loss': 2.4895, 'grad_norm': 9.096225266095017, 'learning_rate': 1.8910065241883678e-07, 'epoch': 0.09}
{'loss': 2.621, 'grad_norm': 8.874010997719317, 'learning_rate': 1.8867736859200618e-07, 'epoch': 0.09}
{'loss': 2.28, 'grad_norm': 5.58540625047692, 'learning_rate': 1.8824651379354558e-07, 'epoch': 0.09}
{'loss': 2.5717, 'grad_norm': 5.121817545128957, 'learning_rate': 1.878081248083698e-07, 'epoch': 0.09}
{'loss': 2.4499, 'grad_norm': 6.576738763968528, 'learning_rate': 1.8736223906463695e-07, 'epoch': 0.1}
{'loss': 2.4083, 'grad_norm': 7.987829207482338, 'learning_rate': 1.8690889463055283e-07, 'epoch': 0.1}
{'loss': 2.4762, 'grad_norm': 20.83910170945999, 'learning_rate': 1.864481302111208e-07, 'epoch': 0.1}
{'loss': 2.4196, 'grad_norm': 5.557629658055064, 'learning_rate': 1.8597998514483723e-07, 'epoch': 0.1}
{'loss': 2.6251, 'grad_norm': 19.325654599711182, 'learning_rate': 1.855044994003331e-07, 'epoch': 0.1}
{'loss': 2.3787, 'grad_norm': 5.360007937331444, 'learning_rate': 1.850217135729614e-07, 'epoch': 0.1}
