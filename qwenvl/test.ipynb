{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae78c1e45134c5b91f4b77a39fcfcaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\n",
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-VL-3B-Instruct\",\n",
    "    torch_dtype=\"auto\",\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-3B-Instruct\", use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused or unrecognized kwargs: fps, return_tensors.\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "import os\n",
    "from decord import VideoReader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/projects/cft_vlm/finetune\")\n",
    "from qwenvl.common_utils import make_model_input\n",
    "processor.tokenizer.padding_side = \"right\"\n",
    "message = [\n",
    "  [\n",
    "      {\n",
    "          \"role\": \"system\",\n",
    "          \"content\": \"You are a student in medicine studying for a final exam.\"\n",
    "      },\n",
    "      {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "              {\"type\": \"text\", \"text\": \"Describe this video\"},\n",
    "              {\"type\": \"video\", \"video\": \"/projects/cft_vlm/openbiomedvid/vid_processed/-0WrCtDe6IQ_8_567.mp4\"},\n",
    "          ]\n",
    "      }\n",
    "  ],\n",
    "  [\n",
    "      {\n",
    "          \"role\": \"system\",\n",
    "          \"content\": \"You are a student in medicine studying for a final exam.\"\n",
    "      },\n",
    "      {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "              {\"type\": \"text\", \"text\": \"Describe this video\"},\n",
    "              {\"type\": \"video\", \"video\": \"/projects/cft_vlm/openbiomedvid/vid_processed/-0zSOhy4mgo_1220_1265.mp4\"}\n",
    "          ]\n",
    "      }\n",
    "  ],  \n",
    "]\n",
    "\n",
    "inputs = make_model_input(\n",
    "    message[0],\n",
    "    processor,\n",
    "    base_interval=1,\n",
    "    video_min_frames=8,\n",
    "    video_max_frames=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused or unrecognized kwargs: fps, return_tensors.\n",
      "Unused or unrecognized kwargs: fps, return_tensors.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/transformers/generation/utils.py:2479: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['system\\nYou are a student in medicine studying for a final exam.\\nuser\\nDescribe this video\\nassistant\\nThe video appears to be an educational resource, likely used for medical students or professionals to learn about various liver conditions and their ultrasound appearances. The content is',\n",
       " 'system\\nYou are a student in medicine studying for a final exam.\\nuser\\nDescribe this video\\nassistant\\nThis image appears to be a slide from a medical presentation, specifically focusing on the clinical characteristics of a condition related to the eye. The title \"Clinical']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qwenvl.common_utils import make_model_input\n",
    "\n",
    "base_interval = 1\n",
    "video_min_frames = 8\n",
    "video_max_frames = 16\n",
    "conversations = message\n",
    "\n",
    "data_dict = make_model_input(\n",
    "    conversations,\n",
    "    processor,\n",
    "    base_interval=base_interval,\n",
    "    video_min_frames=video_min_frames,\n",
    "    video_max_frames=video_max_frames,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "out = model.generate(**data_dict, max_new_tokens=30, do_sample=False)\n",
    "\n",
    "out_txt = processor.tokenizer.batch_decode(out, skip_special_tokens=True)\n",
    "out_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'pixel_values_videos', 'video_grid_thw', 'second_per_grid_ts', 'labels'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "/fs01/projects/cft_vlm/.venv/lib/python3.10/site-packages/transformers/generation/utils.py:2479: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['system\\nYou are a helpful assistant.\\nuser\\nDescribe this video\\nassistant\\nThe provided images are ultrasound scans of the liver, showing various normal and abnormal conditions. Here is a detailed description of each image:\\n\\n1. **Normal']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2 = model.generate(**inputs, max_new_tokens=30, do_sample=False)\n",
    "out2 = processor.tokenizer.batch_decode(out2, skip_special_tokens=True)\n",
    "out2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cft_vlm",
   "language": "python",
   "name": "cft_vlm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
